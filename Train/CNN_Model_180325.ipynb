{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, sys, time, json, codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from inspect import getargspec\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Lambda, merge, concatenate, multiply, Masking, Reshape, RepeatVector\n",
    "from keras.layers import Input, InputLayer, LSTM, Conv1D, Flatten, Dense, Embedding, Dropout, Activation\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.chdir(\"/Users/meif/Desktop/SI 630 NLP/Project/\")\n",
    "\n",
    "from Code.layers.SharedWeight import SharedWeight\n",
    "from Code.layers.VariationalDropout import VariationalDropout\n",
    "from Code.layers.QuestionAttnGRU import QuestionAttnGRU\n",
    "from Code.layers.SelfAttnGRU import SelfAttnGRU\n",
    "from Code.layers.QuestionPooling import QuestionPooling\n",
    "\n",
    "% matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "N_TRAININGPOINTS = \"100000_reidx\"\n",
    "\n",
    "MAX_SEQUENCE_LENGTH_NEWS = 300 # median ~ 650\n",
    "MAX_SENTENCE_LENGTH_NEWS = 19\n",
    "MAX_SEQUENCE_LENGTH_QUES = 46 # max ~ 37\n",
    "MAX_WORD_LENGTH = 15\n",
    "EMBEDDING_DIM_WORD = 100\n",
    "EMBEDDING_DIM_CHAR = 25\n",
    "EMBEDDING_DIM = EMBEDDING_DIM_WORD + EMBEDDING_DIM_CHAR\n",
    "OUTPUT_TYPE = \"multi\"\n",
    "\n",
    "UNK_WORD = \"<UNK_WORD>\"\n",
    "UNK_CHAR = \"^\"\n",
    "UNK_ENTITY = \"<UNK_ENTITY>\"\n",
    "\n",
    "DROPOUT_RATE = 0.2\n",
    "BATCH_SIZE = 35\n",
    "H_DIM = 45\n",
    "NB_EPOCHS = 50\n",
    "\n",
    "BST_MODEL_PATH = 'QA_model.model'\n",
    "MODEL_PATH = 'QA_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Trainset & Valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Found 87355 questions in trainset\n",
      "Found 3579 questions in valset\n",
      "Found 2992 questions in testset\n",
      "Embedding dim: (20109, 100)\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "N_train = np.load(\"Dataset/GRU/{0}/N_train{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_train = np.load(\"Dataset/GRU/{0}/Q_train{0}.npy\".format(N_TRAININGPOINTS))\n",
    "O_train = np.load(\"Dataset/GRU/{0}/O_train{0}.npy\".format(N_TRAININGPOINTS))\n",
    "N_train_char = np.load(\"Dataset/GRU/{0}/N_train_char{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_train_char = np.load(\"Dataset/GRU/{0}/Q_train_char{0}.npy\".format(N_TRAININGPOINTS))\n",
    "\n",
    "N_val = np.load(\"Dataset/GRU/{0}/N_val{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_val = np.load(\"Dataset/GRU/{0}/Q_val{0}.npy\".format(N_TRAININGPOINTS))\n",
    "O_val = np.load(\"Dataset/GRU/{0}/O_val{0}.npy\".format(N_TRAININGPOINTS))\n",
    "N_val_char = np.load(\"Dataset/GRU/{0}/N_val_char{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_val_char = np.load(\"Dataset/GRU/{0}/Q_val_char{0}.npy\".format(N_TRAININGPOINTS))\n",
    "\n",
    "N_test = np.load(\"Dataset/GRU/{0}/N_test{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_test = np.load(\"Dataset/GRU/{0}/Q_test{0}.npy\".format(N_TRAININGPOINTS))\n",
    "O_test = np.load(\"Dataset/GRU/{0}/O_test{0}.npy\".format(N_TRAININGPOINTS))\n",
    "N_test_char = np.load(\"Dataset/GRU/{0}/N_test_char{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_test_char = np.load(\"Dataset/GRU/{0}/Q_test_char{0}.npy\".format(N_TRAININGPOINTS))\n",
    "\n",
    "embedding_matrix = np.load(\"Dataset/GRU/{0}/embedding_word_matrix{0}.npy\".format(N_TRAININGPOINTS))\n",
    "\n",
    "with open(\"Dataset/GRU/{0}/word_index{0}.json\".format(N_TRAININGPOINTS), \"r\") as f:\n",
    "    word_index = json.load(f)\n",
    "with open(\"Dataset/GRU/{0}/entity_index{0}.json\".format(N_TRAININGPOINTS), \"r\") as f:\n",
    "    entity_index = json.load(f)\n",
    "    LABEL_SIZE = len(entity_index)\n",
    "       \n",
    "y_train = np.load(\"Dataset/GRU/{0}/y_train_{1}{0}.npy\".format(N_TRAININGPOINTS, OUTPUT_TYPE))\n",
    "y_val = np.load(\"Dataset/GRU/{0}/y_val_{1}{0}.npy\".format(N_TRAININGPOINTS, OUTPUT_TYPE))\n",
    "y_test = np.load(\"Dataset/GRU/{0}/y_test_{1}{0}.npy\".format(N_TRAININGPOINTS, OUTPUT_TYPE))\n",
    "# y_train = y_train.reshape(43722, 300, 1)\n",
    "# y_val = y_val.reshape(3579, 300, 1)\n",
    "# y_test = y_test.reshape(2992, 300, 1)\n",
    "\n",
    "print(\"Found {} questions in trainset\".format(len(y_train)))\n",
    "print(\"Found {} questions in valset\".format(len(y_val)))\n",
    "print(\"Found {} questions in testset\".format(len(y_test)))\n",
    "print(\"Embedding dim: {}\".format(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0    32    19    33     4     4\n",
      "   458   863     2    11  9735     7 11688     8    20    10  6373    25\n",
      "  4436  2261 18698     3   324   949   136    12    20    25  1070    61\n",
      "     4   489     3    25  3453  2810     6    11     2    98    51  3254\n",
      "  6742     3  1444    17   118  2944     4  8557  1487   160    48  6742\n",
      "     6     1  1007   192     2     1  3742    23  1207     8   397     4\n",
      "   175   520  2914    32   966    13    10     1    14  8273    33     2\n",
      "    67    47  5585    10   114  2965     6     1   145     4   192     3]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0 1047 6241  327\n",
      "   20   15   39  732]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(N_train[0])\n",
    "print(Q_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "       0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix[word_index[\"@entity0\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 RNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNet(Model):\n",
    "    def __init__(self, inputs=None, outputs=None,\n",
    "                       N=MAX_SEQUENCE_LENGTH_NEWS, M=MAX_SEQUENCE_LENGTH_QUES, \n",
    "                       C=MAX_WORD_LENGTH, W=EMBEDDING_DIM_WORD, label_size=LABEL_SIZE, \n",
    "                       embedding_matrix=embedding_matrix, \n",
    "                       hdim=H_DIM, dropout_rate=DROPOUT_RATE, output_type=OUTPUT_TYPE,\n",
    "                       unroll=False, **kwargs):\n",
    "        # Load model from config\n",
    "        if inputs is not None and outputs is not None:\n",
    "            super(RNet, self).__init__(inputs=inputs,\n",
    "                                       outputs=outputs,\n",
    "                                       **kwargs)\n",
    "            return\n",
    "\n",
    "        '''Dimensions'''\n",
    "        B = None\n",
    "        H = hdim\n",
    "\n",
    "        # INPUTS\n",
    "        P_word = Input(shape=(N, ), dtype='int32')\n",
    "        Q_word = Input(shape=(M, ), dtype='int32')\n",
    "        P_char = Input(shape=(N, C), dtype='int32')\n",
    "        Q_char = Input(shape=(M, C), dtype='int32')\n",
    "        input_placeholders = [P_word, P_char, Q_word, Q_char]\n",
    "        \n",
    "        # Word Embedding\n",
    "        P_word = Embedding(len(embedding_matrix), W, weights=[embedding_matrix], trainable=False, input_length=N, name='P_word') (P_word)\n",
    "        Q_word = Embedding(len(embedding_matrix), W, weights=[embedding_matrix], trainable=False, input_length=M, name='Q_word') (Q_word)\n",
    "\n",
    "        # Char Embedding\n",
    "        P_char = TimeDistributed(Embedding(input_dim=67, output_dim=50, input_length=C)) (P_char)\n",
    "        Pc_output = []\n",
    "        for filter_width in [3, 4, 5]:\n",
    "            Pc = TimeDistributed(Conv1D(filters=30,\n",
    "                                 kernel_size=filter_width,\n",
    "                                 activation='relu',\n",
    "                                 border_mode='same',\n",
    "                                 name='Conv1D_Pc_{}'.format(filter_width))) (P_char)\n",
    "            Pc = TimeDistributed(GlobalMaxPooling1D(name='GlobalMaxPooling_Pc_{}'.format(filter_width))) (Pc)\n",
    "            Pc_output.append(Pc)\n",
    "        P_char = merge(Pc_output, mode='concat')\n",
    "        P_char = TimeDistributed(Dropout(dropout_rate)) (P_char)\n",
    "\n",
    "        Q_char = TimeDistributed(Embedding(input_dim=67, output_dim=50)) (Q_char)\n",
    "        Qc_output = []\n",
    "        for filter_width in [3, 4, 5]:\n",
    "            Qc = TimeDistributed(Conv1D(filters=30,\n",
    "                                 kernel_size=filter_width,\n",
    "                                 activation='relu',\n",
    "                                 border_mode='same',\n",
    "                                 name='Conv1D_Qc_{}'.format(filter_width))) (Q_char)\n",
    "            Qc = TimeDistributed(GlobalMaxPooling1D(name='GlobalMaxPooling_Qc_{}'.format(filter_width))) (Qc)\n",
    "            Qc_output.append(Qc)\n",
    "        Q_char = merge(Qc_output, mode='concat')\n",
    "        Q_char = TimeDistributed(Dropout(dropout_rate)) (Q_char)\n",
    "        \n",
    "        # concat word + char\n",
    "        P_vecs = Concatenate() ([P_word, P_char])\n",
    "        Q_vecs = Concatenate() ([Q_word, Q_char])\n",
    "  \n",
    "        P = Concatenate(axis=1) ([P_vecs, Q_vecs])\n",
    "        # uP, uQ shape: [(None, 300, 215), (None, 46, 215)]\n",
    "\n",
    "        # context embedding\n",
    "        uP = Masking() (P_vecs)\n",
    "        for i in range(1):\n",
    "            uP = Bidirectional(GRU(units=H,\n",
    "                                   return_sequences=True,\n",
    "                                   dropout=dropout_rate, unroll=False)) (uP)\n",
    "        uP = VariationalDropout(rate=dropout_rate, noise_shape=(None, 1, 2 * H), name='uP') (uP)\n",
    "       \n",
    "        uQ = Masking() (Q_vecs)\n",
    "        for i in range(1):\n",
    "            uQ = Bidirectional(GRU(units=H,\n",
    "                                   return_sequences=True,\n",
    "                                   dropout=dropout_rate, unroll=False)) (uQ)\n",
    "        uQ = VariationalDropout(rate=dropout_rate, noise_shape=(None, 1, 2 * H), name='uQ') (uQ)\n",
    "    \n",
    "        # uP, uQ shape: [(None, 300, 90), (None, 46, 90)]\n",
    "    \n",
    "        P = Concatenate(axis=1) ([uP, uQ])\n",
    "          \n",
    "        gP = Bidirectional(GRU(units=H, \n",
    "                               return_sequences=False,\n",
    "                               dropout=dropout_rate, unroll=False)) (P)\n",
    "\n",
    "        preds = Dense(label_size, activation='softmax')(gP)\n",
    "             \n",
    "        inputs = input_placeholders\n",
    "        outputs = preds\n",
    "\n",
    "        super(RNet, self).__init__(inputs=inputs, outputs=outputs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=30, kernel_size=3, activation=\"relu\", name=\"Conv1D_Pc_3\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/meif/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1156: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=30, kernel_size=4, activation=\"relu\", name=\"Conv1D_Pc_4\", padding=\"same\")`\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=30, kernel_size=5, activation=\"relu\", name=\"Conv1D_Pc_5\", padding=\"same\")`\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=30, kernel_size=3, activation=\"relu\", name=\"Conv1D_Qc_3\", padding=\"same\")`\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=30, kernel_size=4, activation=\"relu\", name=\"Conv1D_Qc_4\", padding=\"same\")`\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=30, kernel_size=5, activation=\"relu\", name=\"Conv1D_Qc_5\", padding=\"same\")`\n",
      "/Users/meif/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:54: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/meif/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1315: calling reduce_any (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/meif/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/meif/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1331: calling reduce_all (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = RNet(hdim=H_DIM, dropout_rate=DROPOUT_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/meif/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "optimizer_config = {'class_name': 'Adadelta',\n",
    "                    'config': {'epsilon':1e-6}}\n",
    "model.compile(optimizer=optimizer_config,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_7 (InputLayer)             (None, 300, 15)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_8 (InputLayer)             (None, 46, 15)        0                                            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 300, 15, 50)   3350        input_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistribu (None, 46, 15, 50)    3350        input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistribu (None, 300, 15, 30)   4530        time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistribu (None, 300, 15, 30)   6030        time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistribu (None, 300, 15, 30)   7530        time_distributed_1[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_10 (TimeDistrib (None, 46, 15, 30)    4530        time_distributed_9[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistrib (None, 46, 15, 30)    6030        time_distributed_9[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_14 (TimeDistrib (None, 46, 15, 30)    7530        time_distributed_9[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistribu (None, 300, 30)       0           time_distributed_2[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistribu (None, 300, 30)       0           time_distributed_4[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistribu (None, 300, 30)       0           time_distributed_6[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistrib (None, 46, 30)        0           time_distributed_10[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_13 (TimeDistrib (None, 46, 30)        0           time_distributed_12[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_15 (TimeDistrib (None, 46, 30)        0           time_distributed_14[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "input_5 (InputLayer)             (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 300, 90)       0           time_distributed_3[0][0]         \n",
      "                                                                   time_distributed_5[0][0]         \n",
      "                                                                   time_distributed_7[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 46)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 46, 90)        0           time_distributed_11[0][0]        \n",
      "                                                                   time_distributed_13[0][0]        \n",
      "                                                                   time_distributed_15[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "P_word (Embedding)               (None, 300, 100)      2010900     input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistribu (None, 300, 90)       0           merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "Q_word (Embedding)               (None, 46, 100)       2010900     input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistrib (None, 46, 90)        0           merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 300, 190)      0           P_word[0][0]                     \n",
      "                                                                   time_distributed_8[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 46, 190)       0           Q_word[0][0]                     \n",
      "                                                                   time_distributed_16[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "masking_1 (Masking)              (None, 300, 190)      0           concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "masking_2 (Masking)              (None, 46, 190)       0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 300, 90)       63720       masking_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional)  (None, 46, 90)        63720       masking_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "uP (VariationalDropout)          (None, 300, 90)       0           bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "uQ (VariationalDropout)          (None, 46, 90)        0           bidirectional_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)      (None, 346, 90)       0           uP[0][0]                         \n",
      "                                                                   uQ[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional)  (None, 90)            36720       concatenate_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 102)           9282        bidirectional_3[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 4,238,122\n",
      "Trainable params: 216,322\n",
      "Non-trainable params: 4,021,800\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"model_QA_CNN.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0.00001, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10 samples, validate on 3579 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-392503fac5f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_val_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_val_char\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                  callbacks=[checkpoint, early])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_QA_CNN.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                         val_outs = self._test_loop(val_f, val_ins,\n\u001b[1;32m   1092\u001b[0m                                                    \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m                                                    verbose=0)\n\u001b[0m\u001b[1;32m   1094\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1193\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=[N_train[:10], N_train_char[:10], Q_train[:10], Q_train_char[:10]], y=y_train[:10], \n",
    "                 batch_size=BATCH_SIZE, epochs=NB_EPOCHS, \n",
    "                 validation_data=([N_val, N_val_char, Q_val, Q_val_char], y_val),\n",
    "                 callbacks=[checkpoint, early])\n",
    "\n",
    "model.save(\"model_QA_CNN.h5\")\n",
    "print(\"Model saved to {}\".format(\"model_QA_CNN.h5\"))\n",
    "print(min(hist.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the model to predict what color each person is\n",
    "predict_green.fit([sentences_array], [is_green], nb_epoch=5000, verbose=1)\n",
    "embeddings = predict_green.layers[1].W.get_value()\n",
    "\n",
    "# print out the embedding vector associated with each word\n",
    "for i in range(n_words):\n",
    "    print('{}: {}'.format(idx2word[i], embeddings[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# happy learning!\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        P_vecs = Input(shape=(N, ), name='P_vecs')\n",
    "        Q_vecs = Input(shape=(M, ), name='Q_vecs')\n",
    "        P_str = Input(shape=(N,15, ), dtype='int32', name='P_str')\n",
    "        Q_str = Input(shape=(M,15, ), dtype='int32', name='Q_str')\n",
    "        input_placeholders = [P_vecs, P_str, Q_vecs, Q_str]\n",
    "       \n",
    "        P_vecs = Embedding(len(embedding_matrix), W, weights=[embedding_matrix], trainable=False, input_length=N, name='P_vecs') (P_vecs)\n",
    "        Q_vecs = Embedding(len(embedding_matrix), W, weights=[embedding_matrix], trainable=False, input_length=M, name='Q_vecs') (Q_vecs)\n",
    "        P_str = Embedding(65, 25, dropout=dropout_rate, input_length=2100, name='P_str')(P_str)\n",
    "        Q_str = Embedding(65, 25, dropout=dropout_rate, input_length=276, name='Q_str')(Q_str)\n",
    "\n",
    "        uPc1 = Conv1D(nb_filter=25, kernel_size=3, padding='same', activation='relu') (P_str) \n",
    "        uPc2 = Conv1D(nb_filter=25, kernel_size=5, padding='same', activation='relu') (P_str) \n",
    "        uPc3 = Conv1D(nb_filter=25, kernel_size=7, padding='same', activation='relu') (P_str) \n",
    "        uPc1 = MaxPooling1D(pool_length=21) (uPc1)\n",
    "        uPc2 = MaxPooling1D(pool_length=21) (uPc2)\n",
    "        uPc3 = MaxPooling1D(pool_length=21) (uPc3)\n",
    "        uPc = Concatenate(axis=1)([uPc1, uPc2, uPc3])\n",
    "        uPc = Dropout(dropout_rate)(uPc)\n",
    "        \n",
    "        uQc = Conv1D(nb_filter=25, kernel_size=5, padding='same', activation='relu') (Q_str)\n",
    "        uQc = MaxPooling1D(pool_length=6) (uQc1)\n",
    "        uQc = Concatenate(axis=1)([uQc1, uQc2, uQc3])\n",
    "        uQc = Dropout(dropout_rate)(uQc)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
