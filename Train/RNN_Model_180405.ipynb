{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re, sys, time, json, codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from inspect import getargspec\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Conv1D, Flatten, concatenate, multiply, Dense, Input, InputLayer, LSTM, Embedding, Dropout, Activation, Masking, RepeatVector, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.wrappers import Bidirectional, TimeDistributed\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.pooling import GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "os.chdir(\"/Users/meif/Desktop/SI 630 NLP/Project/\")\n",
    "\n",
    "from Code.layers.SharedWeight import SharedWeight\n",
    "from Code.layers.VariationalDropout import VariationalDropout\n",
    "from Code.layers.QuestionAttnGRU import QuestionAttnGRU\n",
    "from Code.layers.SelfAttnGRU import SelfAttnGRU\n",
    "from Code.layers.QuestionPooling import QuestionPooling\n",
    "\n",
    "% matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "N_TRAININGPOINTS = \"10000_reidx\"\n",
    "\n",
    "MAX_SEQUENCE_LENGTH_NEWS = 300 # median ~ 650\n",
    "MAX_SEQUENCE_LENGTH_QUES = 37 # max ~ 37\n",
    "EMBEDDING_DIM_WORD = 100\n",
    "EMBEDDING_DIM_CHAR = 25\n",
    "EMBEDDING_DIM = EMBEDDING_DIM_WORD + EMBEDDING_DIM_CHAR\n",
    "OUTPUT_TYPE = \"multi\"\n",
    "\n",
    "UNK_WORD = \"<UNK_WORD>\"\n",
    "UNK_CHAR = \"^\"\n",
    "UNK_ENTITY = \"<UNK_ENTITY>\"\n",
    "\n",
    "DROPOUT_RATE = 0.3\n",
    "BATCH_SIZE = 50\n",
    "H_DIM = 24\n",
    "NB_EPOCHS = 50\n",
    "\n",
    "BST_MODEL_PATH = 'QA_model.model'\n",
    "MODEL_PATH = 'QA_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(N_data, Q_data, y_data, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    samples_per_epoch = N_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch // batch_size\n",
    "    counter = 0\n",
    "    while True:\n",
    "        N_batch = np.array(N_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
    "        Q_batch = np.array(Q_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
    "        y_batch = np.array(y_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
    "        counter += 1\n",
    "        yield [N_batch, Q_batch], y_batch\n",
    "\n",
    "    if counter <= number_of_batches:\n",
    "        counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Trainset & Valset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "Found 8716 questions in trainset\n",
      "Found 912 questions in valset\n",
      "Found 931 questions in testset\n",
      "Embedding dim: (20182, 125)\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "N_train = np.load(\"Dataset/GRU/{0}/N_train{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_train = np.load(\"Dataset/GRU/{0}/Q_train{0}.npy\".format(N_TRAININGPOINTS))\n",
    "N_val = np.load(\"Dataset/GRU/{0}/N_val{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_val = np.load(\"Dataset/GRU/{0}/Q_val{0}.npy\".format(N_TRAININGPOINTS))\n",
    "N_test = np.load(\"Dataset/GRU/{0}/N_test{0}.npy\".format(N_TRAININGPOINTS))\n",
    "Q_test = np.load(\"Dataset/GRU/{0}/Q_test{0}.npy\".format(N_TRAININGPOINTS))\n",
    "embedding_matrix = np.load(\"Dataset/GRU/{0}/embedding_input_matrix{0}.npy\".format(N_TRAININGPOINTS))\n",
    "option_input = np.load(\"Dataset/GRU/{0}/option_input{0}.npy\".format(N_TRAININGPOINTS))\n",
    "option_input = option_input.reshape(-1,337,1)\n",
    "\n",
    "with open(\"Dataset/GRU/{0}/word_index{0}.json\".format(N_TRAININGPOINTS), \"r\") as f:\n",
    "    word_index = json.load(f)\n",
    "with open(\"Dataset/GRU/{0}/entity_index{0}.json\".format(N_TRAININGPOINTS), \"r\") as f:\n",
    "    entity_index = json.load(f)\n",
    "    LABEL_SIZE = len(entity_index)\n",
    "    \n",
    "y_train = np.load(\"Dataset/GRU/{0}/y_train_{1}{0}.npy\".format(N_TRAININGPOINTS, OUTPUT_TYPE))\n",
    "y_val = np.load(\"Dataset/GRU/{0}/y_val_{1}{0}.npy\".format(N_TRAININGPOINTS, OUTPUT_TYPE))\n",
    "y_test = np.load(\"Dataset/GRU/{0}/y_test_{1}{0}.npy\".format(N_TRAININGPOINTS, OUTPUT_TYPE))\n",
    "\n",
    "print(\"Found {} questions in trainset\".format(len(y_train)))\n",
    "print(\"Found {} questions in valset\".format(len(y_val)))\n",
    "print(\"Found {} questions in testset\".format(len(y_test)))\n",
    "print(\"Embedding dim: {}\".format(embedding_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   51    34    50    10    10   356  1018     2    13 14586     7 17696\n",
      "     6    15     8  8089    23  4039  2339    15     3   121  5221   102\n",
      "     1  4139    10   295  8354  7011     2  1186     1  6675     6    41\n",
      "   165    10   295   881     3   376  1077   106    18    15    23   934\n",
      "    82    10   660     3   436     1   662  5823     6   110  2950  2243\n",
      "     2     1   798  1440    10  4842     6    41   165    10   295   881\n",
      "    30   466     4    15     7  4733  2107   149     3    15    30   573\n",
      "   863     6  1588   475     3    23  2728  2971     9    13     2    55\n",
      "    46  1713  4843     3   131  1309  3015  1769    54  2322     2     8\n",
      "  1602  3015    28  2662     6 15971     3     4  1507    99   348    17\n",
      "  3015     9     1   165    10   295     2  2894   417   291     7 11142\n",
      "     2  2918   132   131  2782  2547    43    28    51   363    12  6676\n",
      "    17     1 15256    50     2     8   420     1 17697    41  4388     4\n",
      "   269   177   437    23     7  1284 11143     3  2098    11    55    30\n",
      "     7   535    51    15     2   927     2  2131     2  1480    50    23\n",
      "     7  1564  1440  2536     2     8  8090    33    67     3  1491    11\n",
      "   127  3300    10  7288  1198   162    35  4843     9     1   871   295\n",
      "     2     1  3363    14   939     6   331    10   236   437  2740    51\n",
      "   744    22     8     1    25  9524    50     2    74    30  6463     8\n",
      "   126  2384     9     1   165    10   295     3    12   131  2537     2\n",
      "     5  3490   295     5    10    10   767     2   162     2   323   622\n",
      "     2   616     8   323   777    10    10  1770     1   267  2919     6\n",
      "  4139    10   295     8   165    10   295 10373     8 12925     3     9\n",
      "  3490   295    55    46  2099  6009  1168     2   208   233     2  2728\n",
      "  2971     8     7   414  3300   862    11    14   169  4039     4  2231]\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0  179 7139  367   15   17   88  722]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(N_train[0])\n",
    "print(Q_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNModel(Model):\n",
    "    def __init__(self, inputs=None, outputs=None,\n",
    "                       N=MAX_SEQUENCE_LENGTH_NEWS, M=MAX_SEQUENCE_LENGTH_QUES, C=EMBEDDING_DIM_CHAR, \n",
    "                       word2vec_dim=EMBEDDING_DIM, label_size=LABEL_SIZE, embedding_matrix=embedding_matrix,\n",
    "                       hdim=H_DIM, dropout_rate=DROPOUT_RATE, output_type=OUTPUT_TYPE,\n",
    "                       unroll=False, **kwargs):\n",
    "        \n",
    "        # Load model from config\n",
    "        if inputs is not None and outputs is not None:\n",
    "            super(RNNModel, self).__init__(inputs=inputs,\n",
    "                                           outputs=outputs,\n",
    "                                           **kwargs)\n",
    "            return\n",
    "\n",
    "        '''Dimensions'''\n",
    "        B = None\n",
    "        H = hdim\n",
    "        W = word2vec_dim\n",
    "        \n",
    "        P_vecs = Input(shape=(N, W), name='P_vecs')\n",
    "        Q_vecs = Input(shape=(M, W), name='Q_vecs')\n",
    "        P_str = Input(shape=(N, C), dtype='int32', name='P_str')\n",
    "        Q_str = Input(shape=(M, C), dtype='int32', name='Q_str')\n",
    "        input_placeholders = [P_vecs, P_str, Q_vecs, Q_str]\n",
    "\n",
    "        P = Embedding(len(embedding_matrix), W, \n",
    "                      weights=[embedding_matrix], trainable=False,\n",
    "                      input_length=N, name='P') (P_vecs)\n",
    "        Q = Embedding(len(embedding_matrix), W, \n",
    "                      weights=[embedding_matrix], trainable=False,\n",
    "                      input_length=M, name='Q') (Q_vecs)\n",
    "        Pc = Embedding(65, 25, \n",
    "                       dropout=dropout_rate,\n",
    "                       input_length=1960)(P_str)\n",
    "    \n",
    "        P = Concatenate() ([P_vecs, P_char_embeddings])\n",
    "        Q = Concatenate() ([Q_vecs, Q_char_embeddings])\n",
    "        \n",
    "        uP = Masking() (P)\n",
    "        for i in range(1):\n",
    "            uP = Bidirectional(GRU(units=H,\n",
    "                                   return_sequences=True,\n",
    "                                   dropout=dropout_rate, unroll=False)) (uP)\n",
    "        uP = VariationalDropout(rate=dropout_rate, noise_shape=(None, 1, 2 * H), name='uP') (uP)\n",
    "\n",
    "        uQ = Masking() (Q)\n",
    "        for i in range(1):\n",
    "            uQ = Bidirectional(GRU(units=H,\n",
    "                                   return_sequences=True,\n",
    "                                   dropout=dropout_rate, unroll=False)) (uQ)\n",
    "        uQ = VariationalDropout(rate=dropout_rate, noise_shape=(None, 1, 2 * H), name='uQ') (uQ)\n",
    "\n",
    "        uPc = Conv1D(nb_filter=nb_filters, filter_length= window_length, \n",
    "                     activation='relu', border_mode='full') (Pc) \n",
    "        char_max_pooling = MaxPooling1D(pool_length=maxCharSize) (char_cnn) #  get output per word. this is the size of the hidden layer\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        merged = concatenate([uP, uQ], axis=1)\n",
    "        \n",
    "        merged = Bidirectional(GRU(units=H, \n",
    "                                   return_sequences=False,\n",
    "                                   dropout=dropout_rate, unroll=False)) (merged)\n",
    "#         preds = TimeDistributed(Dense(1, activation='relu')) (merged)\n",
    "#         preds = multiply([preds, option_input])\n",
    "#         preds = TimeDistributed(Activation('softmax') (preds))\n",
    "        preds = Dense(label_size, activation='softmax')(merged)\n",
    "             \n",
    "        inputs = input_placeholders\n",
    "        outputs = preds\n",
    "\n",
    "        super(RNNModel, self).__init__(inputs=inputs, outputs=outputs, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(hdim=32, dropout_rate=DROPOUT_RATE)\n",
    "optimizer_config = {'class_name': 'sgd',\n",
    "                    'config': {'lr':0.1, 'nesterov':True}}\n",
    "model.compile(optimizer=optimizer_config,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"model_QA_onehot.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0.00001, patience=10, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8716 samples, validate on 912 samples\n",
      "Epoch 1/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3936 - acc: 0.2203Epoch 00000: val_acc did not improve\n",
      "8716/8716 [==============================] - 354s - loss: 2.3931 - acc: 0.2203 - val_loss: 2.4183 - val_acc: 0.2039\n",
      "Epoch 2/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3875 - acc: 0.2259Epoch 00001: val_acc did not improve\n",
      "8716/8716 [==============================] - 320s - loss: 2.3872 - acc: 0.2259 - val_loss: 2.3548 - val_acc: 0.2456\n",
      "Epoch 3/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3735 - acc: 0.2311Epoch 00002: val_acc did not improve\n",
      "8716/8716 [==============================] - 306s - loss: 2.3730 - acc: 0.2313 - val_loss: 2.3771 - val_acc: 0.1524\n",
      "Epoch 4/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3720 - acc: 0.2287Epoch 00003: val_acc improved from 0.24671 to 0.26096, saving model to model_QA_onehot.h5\n",
      "8716/8716 [==============================] - 329s - loss: 2.3715 - acc: 0.2290 - val_loss: 2.3172 - val_acc: 0.2610\n",
      "Epoch 5/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3605 - acc: 0.2348Epoch 00004: val_acc did not improve\n",
      "8716/8716 [==============================] - 353s - loss: 2.3607 - acc: 0.2346 - val_loss: 2.3726 - val_acc: 0.1908\n",
      "Epoch 6/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3587 - acc: 0.2362Epoch 00005: val_acc did not improve\n",
      "8716/8716 [==============================] - 346s - loss: 2.3583 - acc: 0.2361 - val_loss: 2.3680 - val_acc: 0.1524\n",
      "Epoch 7/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3608 - acc: 0.2361Epoch 00006: val_acc did not improve\n",
      "8716/8716 [==============================] - 387s - loss: 2.3608 - acc: 0.2361 - val_loss: 2.4016 - val_acc: 0.2588\n",
      "Epoch 8/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3579 - acc: 0.2255Epoch 00007: val_acc did not improve\n",
      "8716/8716 [==============================] - 332s - loss: 2.3575 - acc: 0.2256 - val_loss: 2.3324 - val_acc: 0.2050\n",
      "Epoch 9/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3581 - acc: 0.2331Epoch 00008: val_acc did not improve\n",
      "8716/8716 [==============================] - 307s - loss: 2.3579 - acc: 0.2331 - val_loss: 2.3498 - val_acc: 0.2039\n",
      "Epoch 10/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3579 - acc: 0.2292Epoch 00009: val_acc did not improve\n",
      "8716/8716 [==============================] - 307s - loss: 2.3576 - acc: 0.2293 - val_loss: 2.3586 - val_acc: 0.2456\n",
      "Epoch 11/50\n",
      "8700/8716 [============================>.] - ETA: 0s - loss: 2.3505 - acc: 0.2375Epoch 00010: val_acc did not improve\n",
      "8716/8716 [==============================] - 313s - loss: 2.3506 - acc: 0.2373 - val_loss: 2.3749 - val_acc: 0.1919\n",
      "Epoch 12/50\n",
      "2200/8716 [======>.......................] - ETA: 246s - loss: 2.3668 - acc: 0.2200"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-54d04b446750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                  callbacks=[checkpoint, early])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# hist = model.fit_generator(generator=generate_data(N_train, Q_train, y_train, BATCH_SIZE),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hist = model.fit(x=[N_train, Q_train], y=y_train, \n",
    "                 batch_size=BATCH_SIZE, epochs=NB_EPOCHS, \n",
    "                 validation_data=([N_val, Q_val], y_val),\n",
    "                 callbacks=[checkpoint, early])\n",
    "\n",
    "# hist = model.fit_generator(generator=generate_data(N_train, Q_train, y_train, BATCH_SIZE),\n",
    "#                     steps_per_epoch=len(N_train) // BATCH_SIZE,\n",
    "#                     validation_data=generate_data(N_val, Q_val, y_val, BATCH_SIZE),\n",
    "#                     validation_steps=len(N_val) // BATCH_SIZE,\n",
    "#                     epochs=NB_EPOCHS,\n",
    "#                     callbacks=[\n",
    "#                         EarlyStopping(monitor='val_loss', patience=10),\n",
    "#                         ModelCheckpoint(MODEL_PATH, verbose=1, save_best_only=True)\n",
    "#                     ])\n",
    "model.save(\"model_QA_onehot.h5\")\n",
    "print(\"Model saved to {}\".format(\"model_QA_onehot.h5\"))\n",
    "print(min(hist.history['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting QA model...\n",
      "931/931 [==============================] - 18s    \n",
      "931/931 [==============================] - 17s    \n",
      "Test loss: 2.2620138351182293\n",
      "Test accuracy: 0.24597207303974222\n",
      "Writing Results\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(hdim=16, dropout_rate=DROPOUT_RATE)\n",
    "optimizer_config = {'class_name': 'sgd', 'config': {'lr':0.1}}\n",
    "model.compile(optimizer=optimizer_config, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights(\"Models/model_QA.h5\")\n",
    "\n",
    "print('Predicting QA model...')\n",
    "y_pred = model.predict(x=[N_test, Q_test], verbose=1)\n",
    "\n",
    "score = model.evaluate([N_test, Q_test], y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print(\"Writing Results\")\n",
    "df = pd.DataFrame({\"y_test\":pd.DataFrame(y_test).idxmax(axis=1), \"y_pred\":pd.DataFrame(y_pred).idxmax(axis=1)})\n",
    "df.to_csv(\"Models/model_QA_acc_{0:.4f}.csv\".format(score[1]), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931/931 [==============================] - 21s    \n",
      "Test loss: 2.2818907052438573\n",
      "Test accuracy: 0.24704618689581095\n",
      "Writing Results\n"
     ]
    }
   ],
   "source": [
    "model = RNNModel(hdim=32, dropout_rate=DROPOUT_RATE)\n",
    "optimizer_config = {'class_name': 'sgd', 'config': {'lr':0.1}}\n",
    "model.compile(optimizer=optimizer_config, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.load_weights(\"Models/model_QA_onehot2.h5\")\n",
    "\n",
    "print('Predicting QA model...')\n",
    "y_pred = model.predict(x=[N_test, Q_test], verbose=1)\n",
    "\n",
    "score = model.evaluate([N_test, Q_test], y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "print(\"Writing Results\")\n",
    "df = pd.DataFrame({\"y_test\":pd.DataFrame(y_test).idxmax(axis=1), \"y_pred\":pd.DataFrame(y_pred).idxmax(axis=1)})\n",
    "df.to_csv(\"Models/model_QA2_acc_{0:.4f}.csv\".format(score[1]), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(5)(x)\n",
    "x = Conv1D(128, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(35)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "prds = Dense(len(labels_index), activation='softmax')(x)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# happy learning!\n",
    "model.fit(x_train, y_train, validation_data=(x_val, y_val),\n",
    "          epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
